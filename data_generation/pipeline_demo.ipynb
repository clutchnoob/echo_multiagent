{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizational Analysis Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the complete pipeline:\n",
    "1. Generate organizational hidden state\n",
    "2. Encode to narrative summary (optional)\n",
    "3. Generate forward forecast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries and set up the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n",
      "✓ Environment loaded\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables (for OpenAI API key)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Import pipeline modules\n",
    "from hidden_state_generation import (\n",
    "    sample_org_seed,\n",
    "    sample_rec_seed,\n",
    "    sample_situation_seed,\n",
    "    OrganizationHiddenState\n",
    ")\n",
    "from encoder_layer import encode_hidden_state_to_text\n",
    "from forward_forecaster import forecast_scenario, forecast_from_file\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(\"✓ Environment loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚠ IMPORTANT: Reload Module Before Generating Forecast\n",
    "\n",
    "**Run the cell below to reload the module and clear any cached versions.**\n",
    "This ensures you're using the latest code with the 'properties' field fix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Module reloaded successfully\n",
      "✓ 'properties' field fix is active\n",
      "\n",
      "You can now run the forecast generation cell below.\n"
     ]
    }
   ],
   "source": [
    "# ⚠ CRITICAL: Reload module to use latest code with 'properties' field fix\n",
    "import importlib\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "# Clear any cached version\n",
    "if 'forward_forecaster' in sys.modules:\n",
    "    del sys.modules['forward_forecaster']\n",
    "\n",
    "# Re-import to get the current file version\n",
    "from forward_forecaster import forecast_scenario, forecast_from_file\n",
    "\n",
    "# Verify the fix is loaded\n",
    "import forward_forecaster\n",
    "source = inspect.getsource(forward_forecaster.forecast_scenario)\n",
    "if 'strip_metadata_fields' in source and \"'properties'\" in source:\n",
    "    print(\"✓ Module reloaded successfully\")\n",
    "    print(\"✓ 'properties' field fix is active\")\n",
    "else:\n",
    "    print(\"⚠ WARNING: Fix may not be loaded - try restarting kernel\")\n",
    "\n",
    "print(\"\\nYou can now run the forecast generation cell below.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Hidden Organizational State\n",
    "\n",
    "Create a synthetic organizational structure with employees, relationships, and context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Seeds:\n",
      "  Organization: {'industry_id': 0, 'size_id': 2, 'power_distance': 0.053821018802222675, 'sanction_salience': 0.22035987277261138, 'in_group_bias': 0.1843718106986697}\n",
      "  Recommendation: {'domain_id': 2, 'theta_ideal': 0.44765529815712257, 'urgency': 0.12405680609965541, 'resource_need': 0.7548499814761097}\n",
      "  Situation: {'theta_current': 0.09159673646522415, 'visibility_flag': 0, 'sanction_strength': 0.6318460965633647, 'provocation_flag': 0}\n"
     ]
    }
   ],
   "source": [
    "# Sample seeds for organization, recommendation, and situation\n",
    "org_seed = sample_org_seed(seed=123)\n",
    "rec_seed = sample_rec_seed(seed=456)\n",
    "sit_seed = sample_situation_seed(seed=789)\n",
    "\n",
    "print(\"Generated Seeds:\")\n",
    "print(f\"  Organization: {org_seed}\")\n",
    "print(f\"  Recommendation: {rec_seed}\")\n",
    "print(f\"  Situation: {sit_seed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated organization with 22 employees\n",
      "\n",
      "Employee Levels:\n",
      "  C-Suite: 1\n",
      "  Director: 4\n",
      "  Manager: 17\n",
      "\n",
      "Departments:\n",
      "  Engineering: 10\n",
      "  Sales: 6\n",
      "  Marketing: 5\n",
      "  HR: 1\n"
     ]
    }
   ],
   "source": [
    "# Generate the full organizational hidden state\n",
    "hidden_state = OrganizationHiddenState(\n",
    "    org_seed=org_seed,\n",
    "    rec_seed=rec_seed,\n",
    "    situation_seed=sit_seed,\n",
    "    departments=['Engineering', 'Marketing', 'Sales', 'HR'],\n",
    "    avg_span_of_control=5\n",
    ")\n",
    "\n",
    "print(f\"✓ Generated organization with {hidden_state.N} employees\")\n",
    "print(f\"\\nEmployee Levels:\")\n",
    "for level, count in hidden_state.levels.items():\n",
    "    print(f\"  {level}: {count}\")\n",
    "\n",
    "print(f\"\\nDepartments:\")\n",
    "dept_counts = hidden_state.employees['department'].value_counts()\n",
    "for dept, count in dept_counts.items():\n",
    "    print(f\"  {dept}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved hidden state to sample_hidden_states/demo_state.json\n",
      "\n",
      "State Summary:\n",
      "  Employees: 22\n",
      "  Industry: tech\n",
      "  Size: large\n",
      "  Recommendation Domain: budget\n",
      "  Graphs: ['reports_to', 'collaboration', 'friendship', 'influence', 'conflict']\n"
     ]
    }
   ],
   "source": [
    "# Convert to JSON and save\n",
    "json_output = hidden_state.to_json_encoding()\n",
    "hidden_state_dict = json.loads(json_output)\n",
    "\n",
    "# Save to file\n",
    "os.makedirs(\"sample_hidden_states\", exist_ok=True)\n",
    "hidden_state_path = \"sample_hidden_states/demo_state.json\"\n",
    "with open(hidden_state_path, \"w\") as f:\n",
    "    f.write(json_output)\n",
    "\n",
    "print(f\"✓ Saved hidden state to {hidden_state_path}\")\n",
    "print(f\"\\nState Summary:\")\n",
    "print(f\"  Employees: {hidden_state_dict['num_employees']}\")\n",
    "print(f\"  Industry: {hidden_state_dict['org_seed']['industry']}\")\n",
    "print(f\"  Size: {hidden_state_dict['org_seed']['size']}\")\n",
    "print(f\"  Recommendation Domain: {hidden_state_dict['rec_seed']['domain']}\")\n",
    "print(f\"  Graphs: {list(hidden_state_dict['graphs'].keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Roster:\n",
      "    employee_id     level   department  tenure  manager_id\n",
      "0             0   C-Suite  Engineering       3          -1\n",
      "1             1  Director        Sales       7           0\n",
      "2             2  Director    Marketing       4           0\n",
      "3             3  Director        Sales       9           0\n",
      "4             4  Director        Sales       3           0\n",
      "5             5   Manager  Engineering       5           3\n",
      "6             6   Manager        Sales       3           4\n",
      "7             7   Manager    Marketing       7           1\n",
      "8             8   Manager        Sales       5           2\n",
      "9             9   Manager  Engineering       9           4\n",
      "10           10   Manager           HR       7           1\n",
      "11           11   Manager        Sales       2           4\n",
      "12           12   Manager  Engineering       4           2\n",
      "13           13   Manager  Engineering       9           3\n",
      "14           14   Manager  Engineering       2           2\n",
      "15           15   Manager  Engineering      10           4\n",
      "16           16   Manager    Marketing       9           3\n",
      "17           17   Manager    Marketing      10           1\n",
      "18           18   Manager  Engineering       5           2\n",
      "19           19   Manager    Marketing       2           3\n",
      "20           20   Manager  Engineering       4           2\n",
      "21           21   Manager  Engineering       7           3\n"
     ]
    }
   ],
   "source": [
    "# Display employee roster\n",
    "print(\"Employee Roster:\")\n",
    "print(hidden_state.employees.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Encode to Narrative Summary (Optional)\n",
    "\n",
    "Convert the structured hidden state into a narrative summary using GPT. This step is optional but can provide useful context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode hidden state to narrative\n",
    "print(\"Encoding hidden state to narrative...\")\n",
    "narrative_json = encode_hidden_state_to_text(hidden_state_path)\n",
    "\n",
    "if narrative_json.startswith(\"Error\"):\n",
    "    print(f\"⚠ {narrative_json}\")\n",
    "    print(\"Skipping encoding step. Continuing with raw hidden state...\")\n",
    "    narrative_data = None\n",
    "else:\n",
    "    narrative_data = json.loads(narrative_json)\n",
    "    \n",
    "    # Save encoded output\n",
    "    os.makedirs(\"sample_encoder_input\", exist_ok=True)\n",
    "    encoded_path = \"sample_encoder_input/demo_encoded.json\"\n",
    "    with open(encoded_path, \"w\") as f:\n",
    "        f.write(narrative_json)\n",
    "    \n",
    "    print(f\"✓ Saved encoded narrative to {encoded_path}\")\n",
    "    print(\"\\nNarrative Summary:\")\n",
    "    print(f\"\\nCompany Description:\\n{narrative_data['company_description'][:200]}...\")\n",
    "    print(f\"\\nKey Relationships:\\n{narrative_data['key_relationships'][:200]}...\")\n",
    "    print(f\"\\nRecommendation Context:\\n{narrative_data['recommendation_context'][:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Forward Forecast\n",
    "\n",
    "Use the hidden state to generate a deterministic forecast of organizational response using GPT with structured outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating forward forecast...\n",
      "(Using OpenAI Structured Outputs with deterministic temperature=0)\n",
      "\n",
      "✓ Forecast generated successfully\n",
      "  - 22 individual sentiment predictions\n"
     ]
    }
   ],
   "source": [
    "# Generate forecast from hidden state\n",
    "print(\"Generating forward forecast...\")\n",
    "print(\"(Using OpenAI Structured Outputs with deterministic temperature=0)\\n\")\n",
    "\n",
    "forecast = forecast_scenario(\n",
    "    hidden_state=hidden_state_dict,\n",
    "    scenario_id=\"demo_scenario\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    prompt_template_id=\"v3\",\n",
    "    horizon=\"decision\"\n",
    ")\n",
    "\n",
    "if \"error\" in forecast and forecast.get(\"error\"):\n",
    "    print(f\"❌ Error: {forecast.get('error_message', 'Unknown error')}\")\n",
    "    print(\"\\nNote: The forecast generation failed.\")\n",
    "    print(\"This may be due to API issues, rate limits, or validation errors.\")\n",
    "else:\n",
    "    print(\"✓ Forecast generated successfully\")\n",
    "    print(f\"  - {len(forecast.get('individual_sentiments', []))} individual sentiment predictions\")\n",
    "    if \"segments\" in forecast:\n",
    "        dept_count = len(forecast.get('segments', {}).get('by_department', {}))\n",
    "        level_count = len(forecast.get('segments', {}).get('by_level', {}))\n",
    "        print(f\"  - {dept_count} departments, {level_count} levels analyzed\")\n",
    "    if \"features_importance\" in forecast:\n",
    "        print(f\"  - {len(forecast.get('features_importance', []))} features analyzed\")\n",
    "    if \"rationale\" in forecast:\n",
    "        print(f\"  - Rationale generated ({len(forecast['rationale'])} chars)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FORECAST RESULTS - SENTIMENT PROPAGATION\n",
      "================================================================================\n",
      "\n",
      "Scenario ID: demo_scenario\n",
      "State Hash: sha256:0d2382692d8ec5d7f0f566d9bc2eacfe31c0fd35490d179f5e6474f5a4feb5f7\n",
      "Horizon: decision\n",
      "Model: gpt-4o-mini (temp=0)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "AGGREGATE OUTCOMES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Top Class: SUPPORT\n",
      "Top Probability: 70.4%\n",
      "\n",
      "Probabilities:\n",
      "  oppose    :   2.1% █░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n",
      "  neutral   :  13.0% ██████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n",
      "  support   :  70.4% ███████████████████████████████████░░░░░░░░░░░░░░░\n",
      "  escalate  :  14.5% ███████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n",
      "\n",
      "  Total: 1.000000 ✓\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "INDIVIDUAL SENTIMENT PROPAGATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total Employees: 22\n",
      "\n",
      "Sentiment Distribution:\n",
      "  support   :  22 employees (100.0%)\n",
      "\n",
      "Detailed Individual Predictions (first 10):\n",
      "\n",
      "  Employee 0: SUPPORT (prob: 0.70)\n",
      "    Influenced by 4 sources:\n",
      "      - Employee 1 via reports_to (weight: 1.00)\n",
      "      - Employee 2 via reports_to (weight: 1.00)\n",
      "      - Employee 3 via reports_to (weight: 1.00)\n",
      "      ... and 1 more\n",
      "\n",
      "  Employee 1: SUPPORT (prob: 0.71)\n",
      "    Influenced by 5 sources:\n",
      "      - Employee 0 via reports_to (weight: 1.00)\n",
      "      - Employee 2 via collaboration (weight: 0.78)\n",
      "      - Employee 3 via collaboration (weight: 0.62)\n",
      "      ... and 2 more\n",
      "\n",
      "  Employee 2: SUPPORT (prob: 0.70)\n",
      "    Influenced by 5 sources:\n",
      "      - Employee 0 via reports_to (weight: 1.00)\n",
      "      - Employee 1 via collaboration (weight: 0.78)\n",
      "      - Employee 3 via collaboration (weight: 0.64)\n",
      "      ... and 2 more\n",
      "\n",
      "  Employee 3: SUPPORT (prob: 0.70)\n",
      "    Influenced by 5 sources:\n",
      "      - Employee 0 via reports_to (weight: 1.00)\n",
      "      - Employee 1 via collaboration (weight: 0.62)\n",
      "      - Employee 2 via collaboration (weight: 0.64)\n",
      "      ... and 2 more\n",
      "\n",
      "  Employee 4: SUPPORT (prob: 0.70)\n",
      "    Influenced by 5 sources:\n",
      "      - Employee 0 via reports_to (weight: 1.00)\n",
      "      - Employee 1 via collaboration (weight: 0.75)\n",
      "      - Employee 2 via collaboration (weight: 0.71)\n",
      "      ... and 2 more\n",
      "\n",
      "  Employee 5: SUPPORT (prob: 0.70)\n",
      "    Influenced by 3 sources:\n",
      "      - Employee 3 via reports_to (weight: 1.00)\n",
      "      - Employee 6 via collaboration (weight: 0.35)\n",
      "      - Employee 9 via friendship (weight: 1.00)\n",
      "\n",
      "  Employee 6: SUPPORT (prob: 0.70)\n",
      "    Influenced by 3 sources:\n",
      "      - Employee 4 via reports_to (weight: 1.00)\n",
      "      - Employee 5 via collaboration (weight: 0.04)\n",
      "      - Employee 8 via friendship (weight: 1.00)\n",
      "\n",
      "  Employee 7: SUPPORT (prob: 0.71)\n",
      "    Influenced by 3 sources:\n",
      "      - Employee 1 via reports_to (weight: 1.00)\n",
      "      - Employee 10 via collaboration (weight: 0.38)\n",
      "      - Employee 17 via friendship (weight: 1.00)\n",
      "\n",
      "  Employee 8: SUPPORT (prob: 0.70)\n",
      "    Influenced by 3 sources:\n",
      "      - Employee 2 via reports_to (weight: 1.00)\n",
      "      - Employee 3 via collaboration (weight: 0.40)\n",
      "      - Employee 11 via friendship (weight: 1.00)\n",
      "\n",
      "  Employee 9: SUPPORT (prob: 0.70)\n",
      "    Influenced by 3 sources:\n",
      "      - Employee 4 via reports_to (weight: 1.00)\n",
      "      - Employee 5 via collaboration (weight: 0.36)\n",
      "      - Employee 12 via friendship (weight: 1.00)\n"
     ]
    }
   ],
   "source": [
    "# Display forecast results\n",
    "if \"error\" not in forecast or not forecast.get(\"error\"):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"FORECAST RESULTS - SENTIMENT PROPAGATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nScenario ID: {forecast['scenario_id']}\")\n",
    "    print(f\"State Hash: {forecast['state_hash']}\")\n",
    "    print(f\"Horizon: {forecast['horizon']}\")\n",
    "    print(f\"Model: {forecast['model']['model']} (temp={forecast['model']['temperature']})\")\n",
    "    \n",
    "    # Display aggregate outcomes\n",
    "    if \"aggregate_outcomes\" in forecast:\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"AGGREGATE OUTCOMES\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        agg = forecast['aggregate_outcomes']\n",
    "        top_class = agg['top_class']\n",
    "        top_prob = agg['probabilities'][top_class]\n",
    "        print(f\"\\nTop Class: {top_class.upper()}\")\n",
    "        print(f\"Top Probability: {top_prob:.1%}\")\n",
    "        \n",
    "        print(\"\\nProbabilities:\")\n",
    "        for cls, prob in agg['probabilities'].items():\n",
    "            bar_length = int(prob * 50)\n",
    "            bar = \"█\" * bar_length + \"░\" * (50 - bar_length)\n",
    "            print(f\"  {cls:10s}: {prob:6.1%} {bar}\")\n",
    "        \n",
    "        total = sum(agg['probabilities'].values())\n",
    "        print(f\"\\n  Total: {total:.6f} {'✓' if abs(total - 1.0) < 1e-6 else '✗'}\")\n",
    "    \n",
    "    # Display individual sentiments\n",
    "    if \"individual_sentiments\" in forecast:\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"INDIVIDUAL SENTIMENT PROPAGATION\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        sentiments = forecast['individual_sentiments']\n",
    "        print(f\"\\nTotal Employees: {len(sentiments)}\")\n",
    "        \n",
    "        # Count by sentiment\n",
    "        sentiment_counts = {}\n",
    "        for s in sentiments:\n",
    "            sent = s.get(\"sentiment\", \"unknown\")\n",
    "            sentiment_counts[sent] = sentiment_counts.get(sent, 0) + 1\n",
    "        \n",
    "        print(f\"\\nSentiment Distribution:\")\n",
    "        for sent, count in sorted(sentiment_counts.items()):\n",
    "            pct = count / len(sentiments) * 100\n",
    "            print(f\"  {sent:10s}: {count:3d} employees ({pct:5.1f}%)\")\n",
    "        \n",
    "        # Show detailed examples\n",
    "        print(f\"\\nDetailed Individual Predictions (first 10):\")\n",
    "        for s in sentiments[:10]:\n",
    "            emp_id = s.get(\"employee_id\", \"?\")\n",
    "            sent = s.get(\"sentiment\", \"?\")\n",
    "            prob = s.get(\"probabilities\", {}).get(sent, 0)\n",
    "            influences = s.get(\"influence_sources\", [])\n",
    "            path = s.get(\"propagation_path\", [])\n",
    "            \n",
    "            print(f\"\\n  Employee {emp_id}: {sent.upper()} (prob: {prob:.2f})\")\n",
    "            if influences:\n",
    "                print(f\"    Influenced by {len(influences)} sources:\")\n",
    "                for inf in influences[:3]:  # Show first 3\n",
    "                    print(f\"      - Employee {inf['employee_id']} via {inf['graph_type']} (weight: {inf['influence_weight']:.2f})\")\n",
    "                if len(influences) > 3:\n",
    "                    print(f\"      ... and {len(influences) - 3} more\")\n",
    "            if path:\n",
    "                print(f\"    Propagation path: {' → '.join(map(str, path))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display segment analysis if available\n",
    "if \"error\" not in forecast or not forecast.get(\"error\"):\n",
    "    if \"segments\" in forecast:\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"SEGMENT ANALYSIS\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        segments = forecast['segments']\n",
    "        \n",
    "        if \"by_department\" in segments:\n",
    "            print(\"\\nBy Department:\")\n",
    "            for dept, probs in segments[\"by_department\"].items():\n",
    "                top = max(probs.items(), key=lambda x: x[1])\n",
    "                print(f\"  {dept:15s}: {top[0]:10s} ({top[1]:.1%})\")\n",
    "        \n",
    "        if \"by_level\" in segments:\n",
    "            print(\"\\nBy Level:\")\n",
    "            for level, probs in segments[\"by_level\"].items():\n",
    "                top = max(probs.items(), key=lambda x: x[1])\n",
    "                print(f\"  {level:15s}: {top[0]:10s} ({top[1]:.1%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RATIONALE & INSIGHTS\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display rationale and insights\n",
    "if \"error\" not in forecast or not forecast.get(\"error\"):\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"RATIONALE & INSIGHTS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    if \"rationale\" in forecast:\n",
    "        print(f\"\\nRationale:\\n{forecast['rationale']}\")\n",
    "    \n",
    "    if \"features_importance\" in forecast and forecast[\"features_importance\"]:\n",
    "        print(\"\\nKey Features:\")\n",
    "        for feature in forecast[\"features_importance\"][:5]:\n",
    "            direction_symbol = \"↑\" if feature[\"direction\"] == \"+\" else \"↓\"\n",
    "            print(f\"  {direction_symbol} {feature['feature']:30s} (weight: {feature['weight']:.2f})\")\n",
    "    \n",
    "    if \"constraints_used\" in forecast and forecast[\"constraints_used\"]:\n",
    "        print(\"\\nConstraints:\")\n",
    "        for constraint in forecast[\"constraints_used\"]:\n",
    "            print(f\"  • {constraint}\")\n",
    "    \n",
    "    if \"warnings\" in forecast and forecast[\"warnings\"]:\n",
    "        print(\"\\nWarnings:\")\n",
    "        for warning in forecast[\"warnings\"]:\n",
    "            print(f\"  ⚠ {warning}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved forecast to sample_forecasts/demo_forecast.json\n"
     ]
    }
   ],
   "source": [
    "# Save forecast to file\n",
    "# Save even if there's an error, so we can inspect what was generated\n",
    "os.makedirs(\"sample_forecasts\", exist_ok=True)\n",
    "forecast_path = \"sample_forecasts/demo_forecast.json\"\n",
    "with open(forecast_path, \"w\") as f:\n",
    "    json.dump(forecast, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Saved forecast to {forecast_path}\")\n",
    "if \"error\" in forecast and forecast.get(\"error\"):\n",
    "    print(f\"⚠ Note: Forecast has validation errors - see 'error_message' field\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The pipeline has completed successfully:\n",
    "\n",
    "1. ✅ Generated organizational hidden state\n",
    "2. ✅ Encoded to narrative (if API available)\n",
    "3. ✅ Generated forward forecast\n",
    "\n",
    "### Files Generated:\n",
    "- `sample_hidden_states/demo_state.json` - Raw organizational state\n",
    "- `sample_encoder_input/demo_encoded.json` - Narrative summary (if encoding succeeded)\n",
    "- `sample_forecasts/demo_forecast.json` - Forecast results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key forecast statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FORECAST SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if \"error\" in forecast and forecast.get(\"error\"):\n",
    "    print(f\"\\n❌ Error: {forecast.get('error_message', 'Unknown error')}\")\n",
    "else:\n",
    "    print(\"\\n✓ Forecast generated successfully\")\n",
    "    \n",
    "    print(f\"\\nKey Statistics:\")\n",
    "    print(f\"  - Individual Sentiments: {len(forecast.get('individual_sentiments', []))}\")\n",
    "    \n",
    "    if \"segments\" in forecast:\n",
    "        dept_count = len(forecast.get('segments', {}).get('by_department', {}))\n",
    "        level_count = len(forecast.get('segments', {}).get('by_level', {}))\n",
    "        print(f\"  - Departments: {dept_count}\")\n",
    "        print(f\"  - Levels: {level_count}\")\n",
    "    \n",
    "    if \"features_importance\" in forecast:\n",
    "        print(f\"  - Features Analyzed: {len(forecast.get('features_importance', []))}\")\n",
    "    \n",
    "    if forecast.get('aggregate_outcomes'):\n",
    "        top_class = forecast['aggregate_outcomes'].get('top_class', 'unknown')\n",
    "        top_prob = forecast['aggregate_outcomes'].get('probabilities', {}).get(top_class, 0)\n",
    "        print(f\"\\n  Aggregate Top Class: {top_class.upper()} ({top_prob:.1%})\")\n",
    "    \n",
    "    print(f\"\\n  Model: {forecast.get('model', {}).get('model', 'unknown')} (temp={forecast.get('model', {}).get('temperature', 'unknown')})\")\n",
    "    print(f\"  State Hash: {forecast.get('state_hash', 'unknown')[:20]}...\")\n",
    "\n",
    "# Optionally display full JSON (commented out to avoid clutter)\n",
    "# print(\"\\nFull Forecast JSON:\")\n",
    "# print(json.dumps(forecast, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
